{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SVM Binary Baseline.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wutnfmqFCSJY"
      },
      "source": [
        "# SVM Baseline with TF-IDF Encodings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gC0ICZqvCXTE"
      },
      "source": [
        "Reference code: https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jcLLbngG6--"
      },
      "source": [
        "import csv\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import math\n",
        "import random\n",
        "from sklearn.metrics import confusion_matrix"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uB_NsXYRhR4Z"
      },
      "source": [
        "import nltk\n",
        "import re\n",
        "import warnings\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn import svm\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn import metrics\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N11oGSHnhn5i"
      },
      "source": [
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K35U_voihqyO"
      },
      "source": [
        "df = pd.read_csv('train1_binary.csv') \n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ph6HqjBkhq8y"
      },
      "source": [
        "def preprocess(df):\n",
        "    df['comment_text'] = df.comment_text.str.lower()\n",
        "    df['document_sentences'] = df.comment_text.str.split('.') \n",
        "    df['tokenized_sentences'] = list(map(lambda sentences: list(map(nltk.word_tokenize, sentences)), df.document_sentences))  \n",
        "    df['tokenized_sentences'] = list(map(lambda sentences: list(filter(lambda lst: lst, sentences)), df.tokenized_sentences))\n",
        "\n",
        "preprocess(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k2wwG2OphrEs"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train, test, y_train, y_test = train_test_split(df.drop(columns='label'), df['label'], test_size=.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pS6bK-5siGdS"
      },
      "source": [
        "def remove_items(test_list, item):\n",
        "    # utility function to remove stop words\n",
        "    for i in test_list:\n",
        "        if(i == item):\n",
        "            test_list.remove(i)\n",
        "  \n",
        "    return test_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N2dJV0KYiGm-"
      },
      "source": [
        "def preprocess_text(sen):\n",
        "    sentence = sen.lower()\n",
        "    # Remove punctuations and numbers\n",
        "    sentence = re.sub('[^a-zA-Z]', ' ', sentence)\n",
        "\n",
        "    # Single character removal\n",
        "    sentence = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', sentence)\n",
        "\n",
        "    # Removing multiple spaces\n",
        "    sentence = re.sub(r'\\s+', ' ', sentence)\n",
        "\n",
        "    # Remove extra spaces\n",
        "    sentence = re.sub(' +', ' ', sentence)\n",
        "    sentence_list = sentence.split()\n",
        "\n",
        "    # Removing stop words\n",
        "    stop_words = ['u', 'ur', 'im', 'can', 'cant', 'i', 'me', 'my', 'myself', 'we', 'go', 'our', 'ours', 'ourselves', 'you', \"youre\", \"youve\", \"youll\", \"youd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'it', 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"thatll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"shouldve\", 'now', 'd', 'll', 'm', 'o', 're', 'r', 'ur', 've', 'y', 'ain', 'aren', \"arent\", 'couldn', \"couldnt\", 'didn', \"didnt\", 'doesn', \"doesnt\", 'hadn', \"hadnt\", 'hasn', \"hasnt\", 'haven', \"havent\", 'isn', \"isnt\", 'ma', 'mightn', \"mightnt\", 'mustn', \"mustnt\", 'needn', \"neednt\", 'shan', \"shant\", 'shouldn', \"shouldnt\", 'wasn', \"wasnt\", 'weren', \"werent\", 'won', \"wont\", 'wouldn', \"wouldnt\"]\n",
        "    for stop_word in stop_words:\n",
        "      if stop_word in sentence_list:\n",
        "        sentence_list = remove_items(sentence_list, stop_word)\n",
        "\n",
        "    # Join back to list\n",
        "    sentence = \" \".join(sentence_list)\n",
        "\n",
        "    # Remove extra spaces\n",
        "    sentence = re.sub(' +', ' ', sentence)\n",
        "    return sentence.lstrip()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dldWGFeLiG04"
      },
      "source": [
        "X_train = []\n",
        "sentences = list(train[\"comment_text\"])\n",
        "for sen in sentences:\n",
        "    X_train.append(preprocess_text(sen))  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZEuCcmeiL5Z"
      },
      "source": [
        "X_test = []\n",
        "sentences1 = list(test[\"comment_text\"])\n",
        "for sen in sentences1:\n",
        "    X_test.append(preprocess_text(sen))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_lsOB-PbiMDb"
      },
      "source": [
        "vectorizer = TfidfVectorizer(stop_words='english')\n",
        "X_train_matrix = vectorizer.fit_transform(X_train)\n",
        "X_test_matrix = vectorizer.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9t4PVzZ2iVCu"
      },
      "source": [
        "clf = svm.SVC(kernel='poly')\n",
        "clf.fit(X_train_matrix, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z95p4fZYiVKk"
      },
      "source": [
        "predictions = clf.predict(X_test_matrix)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dvpaduTriy9C"
      },
      "source": [
        "print(classification_report(y_test, predictions))\n",
        "print(confusion_matrix(y_test, predictions, normalize='true'))\n",
        "print(\"Accuracy:\",metrics.accuracy_score(y_test, predictions))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}