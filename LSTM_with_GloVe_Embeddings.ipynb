{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM with GloVe Embeddings.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fOJJITkCL_Fj"
      },
      "source": [
        "# LSTM with GloVe Embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wI4_X7YMMEem"
      },
      "source": [
        "Source: https://stackabuse.com/python-for-nlp-multi-label-text-classification-with-keras/#disqus_thread"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fx4ZkxwyMKkK"
      },
      "source": [
        "# Imports and Pre-Processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yV8Zm_n0MZ3I"
      },
      "source": [
        "from numpy import array\n",
        "from keras.preprocessing.text import one_hot\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Activation, Dropout, Dense\n",
        "from keras.layers import Flatten, LSTM\n",
        "from keras.layers import GlobalMaxPooling1D\n",
        "from keras.models import Model\n",
        "from keras.layers.embeddings import Embedding\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.layers import Input\n",
        "from keras.layers.merge import Concatenate\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "\n",
        "from numpy import array\n",
        "from numpy import asarray\n",
        "from numpy import zeros\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bgVvERNAMjrM"
      },
      "source": [
        "Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_6yn-9RMawI"
      },
      "source": [
        "comments = pd.read_csv(\"train1_onehot_full.csv\")\n",
        "print(comments.shape)\n",
        "comments.head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EbtZSnXXGKSs"
      },
      "source": [
        "Remove all rows that contain a null value or empty string"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MRdj-CT1F-_F"
      },
      "source": [
        "filter = comments[\"comment_text\"] != \"\"\n",
        "comments = comments[filter]\n",
        "comments = comments.dropna()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aYyiJZO4GdRH"
      },
      "source": [
        "Print a random comment, and print its associated labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-kfPU53mGWoH",
        "outputId": "4a6f0863-5984-43d1-edc2-96f9aaf60838"
      },
      "source": [
        "print(comments[\"comment_text\"][160])\n",
        "print(\"Neutral:\" + str(comments[\"neutral\"][160]))\n",
        "print(\"Toxic:\" + str(comments[\"toxic\"][160]))\n",
        "print(\"Derogatory:\" + str(comments[\"derogatory\"][160]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "really terrible\n",
            "Neutral:0\n",
            "Toxic:1\n",
            "Derogatory:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9k-n8-NHmaP"
      },
      "source": [
        "Plot the comment count for each label"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8lVUHYgbGaKh"
      },
      "source": [
        "comments_labels = comments[[\"neutral\", \"toxic\", \"derogatory\"]]\n",
        "comments_labels.head()\n",
        "print(comments_labels.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "umhu5F9wHwzf"
      },
      "source": [
        "fig_size = plt.rcParams[\"figure.figsize\"]\n",
        "fig_size[0] = 8\n",
        "fig_size[1] = 6\n",
        "plt.rcParams[\"figure.figsize\"] = fig_size\n",
        "plt.title('Dataset balances')\n",
        "\n",
        "print(comments_labels.sum(axis=0) / 38640)\n",
        "labels_to_plot = [(comments_labels.sum(axis=0))[0], (comments_labels.sum(axis=0))[1], (comments_labels.sum(axis=0))[2]]\n",
        "plt.bar(['neutral/positive', 'neg. attitude', 'derogatory'], labels_to_plot, width=0.35, align='center')\n",
        "plt.ylim(0, 0.7)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kw55NN6gMsnw"
      },
      "source": [
        "def remove_items(test_list, item):\n",
        "    # remove the item for all its occurrences\n",
        "    for i in test_list:\n",
        "        if(i == item):\n",
        "            test_list.remove(i)\n",
        "  \n",
        "    return test_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qTf4963T8paq"
      },
      "source": [
        "def preprocess_text(sen):\n",
        "    sentence = sen.lower()\n",
        "    # Remove punctuations and numbers\n",
        "    sentence = re.sub('[^a-zA-Z]', ' ', sentence)\n",
        "\n",
        "    # Single character removal\n",
        "    sentence = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', sentence)\n",
        "\n",
        "    # Removing multiple spaces\n",
        "    sentence = re.sub(r'\\s+', ' ', sentence)\n",
        "\n",
        "    # Remove extra spaces\n",
        "    sentence = re.sub(' +', ' ', sentence)\n",
        "    sentence_list = sentence.split()\n",
        "\n",
        "    # Removing stop words\n",
        "    stop_words = ['u', 'ur', 'im', 'can', 'cant', 'i', 'me', 'my', 'myself', 'we', 'go', 'our', 'ours', 'ourselves', 'you', \"youre\", \"youve\", \"youll\", \"youd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'it', 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"thatll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"shouldve\", 'now', 'd', 'll', 'm', 'o', 're', 'r', 'ur', 've', 'y', 'ain', 'aren', \"arent\", 'couldn', \"couldnt\", 'didn', \"didnt\", 'doesn', \"doesnt\", 'hadn', \"hadnt\", 'hasn', \"hasnt\", 'haven', \"havent\", 'isn', \"isnt\", 'ma', 'mightn', \"mightnt\", 'mustn', \"mustnt\", 'needn', \"neednt\", 'shan', \"shant\", 'shouldn', \"shouldnt\", 'wasn', \"wasnt\", 'weren', \"werent\", 'won', \"wont\", 'wouldn', \"wouldnt\"]\n",
        "    for stop_word in stop_words:\n",
        "      if stop_word in sentence_list:\n",
        "        sentence_list = remove_items(sentence_list, stop_word)\n",
        "\n",
        "    # Join back to list\n",
        "    sentence = \" \".join(sentence_list)\n",
        "\n",
        "    # Remove extra spaces\n",
        "    sentence = re.sub(' +', ' ', sentence)\n",
        "    return sentence.lstrip()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZkfeyditP2Lu"
      },
      "source": [
        "Get a list of all sentences and labels from the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tlx1JTmd8usJ"
      },
      "source": [
        "X = []\n",
        "sentences = list(comments[\"comment_text\"])\n",
        "for sen in sentences:\n",
        "    X.append(preprocess_text(sen))\n",
        "\n",
        "y = comments_labels.values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PObnL5DhQEXF"
      },
      "source": [
        "Split data into training and test sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rjqQ5aO_wjy5"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tDVa_qkBttZ1"
      },
      "source": [
        "# Tokenizing and GloVe Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NErXiyWSYvCQ"
      },
      "source": [
        "tokenizer = Tokenizer(num_words=1000)\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "\n",
        "X_train = tokenizer.texts_to_sequences(X_train)\n",
        "X_test = tokenizer.texts_to_sequences(X_test)\n",
        "\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "print(vocab_size)\n",
        "maxlen = 10\n",
        "\n",
        "X_train = pad_sequences(X_train, padding='post', maxlen=maxlen)\n",
        "X_test = pad_sequences(X_test, padding='post', maxlen=maxlen)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y1ZB562LQMHg"
      },
      "source": [
        "Get GloVe embeddings. The embedding matrix will be fed into the neural network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQVQ3Ld3ZFeu"
      },
      "source": [
        "embeddings_dictionary = dict()\n",
        "glove_file = open('glove.6B.50d.txt', encoding=\"utf8\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ohoAWqscZGyM"
      },
      "source": [
        "for line in glove_file:\n",
        "    records = line.split()\n",
        "    word = records[0]\n",
        "    vector_dimensions = asarray(records[1:], dtype='float32')\n",
        "    embeddings_dictionary[word] = vector_dimensions\n",
        "glove_file.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-XUh9u-fRnp"
      },
      "source": [
        "embedding_matrix = zeros((vocab_size, 50))\n",
        "for word, index in tokenizer.word_index.items():\n",
        "    embedding_vector = embeddings_dictionary.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[index] = embedding_vector"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H8MZA0ITmeXr"
      },
      "source": [
        "Specify the model architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xLsuanlmlkcI"
      },
      "source": [
        "print(vocab_size)\n",
        "deep_inputs = Input(shape=(maxlen,))\n",
        "embedding_layer = Embedding(vocab_size, 50, weights=[embedding_matrix], trainable=False)(deep_inputs)\n",
        "LSTM_Layer_1 = LSTM(50)(embedding_layer)\n",
        "dense_layer_1 = Dense(3, activation='sigmoid')(LSTM_Layer_1)\n",
        "model = Model(inputs=deep_inputs, outputs=dense_layer_1)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9AHq9QL_l4Jz"
      },
      "source": [
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yK-13sDomxDN"
      },
      "source": [
        "from keras.utils import plot_model\n",
        "plot_model(model, to_file='model_plot4a.png', show_shapes=True, show_layer_names=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qIWl5snYQYAt"
      },
      "source": [
        "# Training and Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wZYMhZ7rm9zT",
        "outputId": "215b8a7c-7d66-46e4-82b8-d7e2a78d988d"
      },
      "source": [
        "history = model.fit(X_train, y_train, batch_size=30, epochs=300, verbose=1, validation_split=0.20)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "825/825 [==============================] - 8s 8ms/step - loss: 0.5896 - acc: 0.7756 - val_loss: 0.3197 - val_acc: 0.8931\n",
            "Epoch 2/300\n",
            "825/825 [==============================] - 6s 7ms/step - loss: 0.3010 - acc: 0.9046 - val_loss: 0.2849 - val_acc: 0.9065\n",
            "Epoch 3/300\n",
            "825/825 [==============================] - 6s 7ms/step - loss: 0.2558 - acc: 0.9180 - val_loss: 0.2696 - val_acc: 0.9123\n",
            "Epoch 4/300\n",
            "825/825 [==============================] - 6s 7ms/step - loss: 0.2350 - acc: 0.9253 - val_loss: 0.2475 - val_acc: 0.9199\n",
            "Epoch 5/300\n",
            "825/825 [==============================] - 6s 7ms/step - loss: 0.2219 - acc: 0.9284 - val_loss: 0.2407 - val_acc: 0.9224\n",
            "Epoch 6/300\n",
            "825/825 [==============================] - 5s 7ms/step - loss: 0.2262 - acc: 0.9252 - val_loss: 0.2332 - val_acc: 0.9275\n",
            "Epoch 7/300\n",
            "825/825 [==============================] - 5s 7ms/step - loss: 0.2071 - acc: 0.9327 - val_loss: 0.2356 - val_acc: 0.9246\n",
            "Epoch 8/300\n",
            "825/825 [==============================] - 5s 7ms/step - loss: 0.1969 - acc: 0.9364 - val_loss: 0.2137 - val_acc: 0.9293\n",
            "Epoch 9/300\n",
            "825/825 [==============================] - 5s 6ms/step - loss: 0.1919 - acc: 0.9386 - val_loss: 0.2165 - val_acc: 0.9277\n",
            "Epoch 10/300\n",
            "825/825 [==============================] - 5s 7ms/step - loss: 0.1837 - acc: 0.9396 - val_loss: 0.2090 - val_acc: 0.9316\n",
            "Epoch 11/300\n",
            "825/825 [==============================] - 5s 6ms/step - loss: 0.1842 - acc: 0.9417 - val_loss: 0.2044 - val_acc: 0.9343\n",
            "Epoch 12/300\n",
            "825/825 [==============================] - 6s 7ms/step - loss: 0.1802 - acc: 0.9410 - val_loss: 0.2028 - val_acc: 0.9343\n",
            "Epoch 13/300\n",
            "825/825 [==============================] - 7s 8ms/step - loss: 0.1777 - acc: 0.9418 - val_loss: 0.2240 - val_acc: 0.9250\n",
            "Epoch 14/300\n",
            "825/825 [==============================] - 6s 7ms/step - loss: 0.1767 - acc: 0.9414 - val_loss: 0.1949 - val_acc: 0.9363\n",
            "Epoch 15/300\n",
            "825/825 [==============================] - 5s 6ms/step - loss: 0.1752 - acc: 0.9415 - val_loss: 0.1901 - val_acc: 0.9405\n",
            "Epoch 16/300\n",
            "825/825 [==============================] - 5s 6ms/step - loss: 0.1702 - acc: 0.9430 - val_loss: 0.1872 - val_acc: 0.9402\n",
            "Epoch 17/300\n",
            "825/825 [==============================] - 5s 6ms/step - loss: 0.1621 - acc: 0.9464 - val_loss: 0.1859 - val_acc: 0.9400\n",
            "Epoch 18/300\n",
            "825/825 [==============================] - 5s 6ms/step - loss: 0.1610 - acc: 0.9461 - val_loss: 0.1812 - val_acc: 0.9411\n",
            "Epoch 19/300\n",
            "825/825 [==============================] - 5s 6ms/step - loss: 0.1602 - acc: 0.9450 - val_loss: 0.1809 - val_acc: 0.9426\n",
            "Epoch 20/300\n",
            "825/825 [==============================] - 5s 6ms/step - loss: 0.1456 - acc: 0.9514 - val_loss: 0.1817 - val_acc: 0.9402\n",
            "Epoch 21/300\n",
            "825/825 [==============================] - 5s 6ms/step - loss: 0.1553 - acc: 0.9469 - val_loss: 0.1800 - val_acc: 0.9402\n",
            "Epoch 22/300\n",
            "825/825 [==============================] - 5s 6ms/step - loss: 0.1457 - acc: 0.9504 - val_loss: 0.1832 - val_acc: 0.9427\n",
            "Epoch 23/300\n",
            "825/825 [==============================] - 5s 6ms/step - loss: 0.1484 - acc: 0.9485 - val_loss: 0.1835 - val_acc: 0.9416\n",
            "Epoch 24/300\n",
            "825/825 [==============================] - 5s 6ms/step - loss: 0.1520 - acc: 0.9472 - val_loss: 0.1800 - val_acc: 0.9411\n",
            "Epoch 25/300\n",
            "825/825 [==============================] - 5s 6ms/step - loss: 0.1484 - acc: 0.9485 - val_loss: 0.1767 - val_acc: 0.9429\n",
            "Epoch 26/300\n",
            "825/825 [==============================] - 5s 6ms/step - loss: 0.1421 - acc: 0.9506 - val_loss: 0.1750 - val_acc: 0.9439\n",
            "Epoch 27/300\n",
            "825/825 [==============================] - 5s 6ms/step - loss: 0.1516 - acc: 0.9479 - val_loss: 0.1750 - val_acc: 0.9413\n",
            "Epoch 28/300\n",
            "825/825 [==============================] - 6s 7ms/step - loss: 0.1475 - acc: 0.9477 - val_loss: 0.1713 - val_acc: 0.9427\n",
            "Epoch 29/300\n",
            "825/825 [==============================] - 5s 6ms/step - loss: 0.1529 - acc: 0.9476 - val_loss: 0.1688 - val_acc: 0.9434\n",
            "Epoch 30/300\n",
            "825/825 [==============================] - 5s 7ms/step - loss: 0.1450 - acc: 0.9501 - val_loss: 0.1693 - val_acc: 0.9450\n",
            "Epoch 31/300\n",
            "825/825 [==============================] - 5s 7ms/step - loss: 0.1440 - acc: 0.9503 - val_loss: 0.1818 - val_acc: 0.9400\n",
            "Epoch 32/300\n",
            "825/825 [==============================] - 5s 6ms/step - loss: 0.1464 - acc: 0.9492 - val_loss: 0.1717 - val_acc: 0.9445\n",
            "Epoch 33/300\n",
            "825/825 [==============================] - 5s 6ms/step - loss: 0.1354 - acc: 0.9542 - val_loss: 0.1713 - val_acc: 0.9444\n",
            "Epoch 34/300\n",
            "825/825 [==============================] - 6s 7ms/step - loss: 0.1495 - acc: 0.9472 - val_loss: 0.1679 - val_acc: 0.9453\n",
            "Epoch 35/300\n",
            "825/825 [==============================] - 6s 7ms/step - loss: 0.1386 - acc: 0.9516 - val_loss: 0.1668 - val_acc: 0.9448\n",
            "Epoch 36/300\n",
            "825/825 [==============================] - 6s 7ms/step - loss: 0.1404 - acc: 0.9505 - val_loss: 0.1651 - val_acc: 0.9466\n",
            "Epoch 37/300\n",
            "825/825 [==============================] - 6s 7ms/step - loss: 0.1358 - acc: 0.9523 - val_loss: 0.1718 - val_acc: 0.9455\n",
            "Epoch 38/300\n",
            "825/825 [==============================] - 7s 8ms/step - loss: 0.1371 - acc: 0.9526 - val_loss: 0.1693 - val_acc: 0.9442\n",
            "Epoch 39/300\n",
            "825/825 [==============================] - 6s 7ms/step - loss: 0.1449 - acc: 0.9492 - val_loss: 0.1643 - val_acc: 0.9457\n",
            "Epoch 40/300\n",
            "825/825 [==============================] - 6s 8ms/step - loss: 0.1292 - acc: 0.9561 - val_loss: 0.2124 - val_acc: 0.9324\n",
            "Epoch 41/300\n",
            "825/825 [==============================] - 6s 8ms/step - loss: 0.1494 - acc: 0.9482 - val_loss: 0.1681 - val_acc: 0.9447\n",
            "Epoch 42/300\n",
            "825/825 [==============================] - 6s 7ms/step - loss: 0.1343 - acc: 0.9538 - val_loss: 0.1652 - val_acc: 0.9460\n",
            "Epoch 43/300\n",
            "825/825 [==============================] - 6s 7ms/step - loss: 0.1353 - acc: 0.9516 - val_loss: 0.1610 - val_acc: 0.9452\n",
            "Epoch 44/300\n",
            "825/825 [==============================] - 6s 7ms/step - loss: 0.1377 - acc: 0.9514 - val_loss: 0.1629 - val_acc: 0.9471\n",
            "Epoch 45/300\n",
            "825/825 [==============================] - 6s 8ms/step - loss: 0.1332 - acc: 0.9529 - val_loss: 0.1647 - val_acc: 0.9470\n",
            "Epoch 46/300\n",
            "825/825 [==============================] - 6s 7ms/step - loss: 0.1371 - acc: 0.9513 - val_loss: 0.1700 - val_acc: 0.9423\n",
            "Epoch 47/300\n",
            "825/825 [==============================] - 6s 7ms/step - loss: 0.1363 - acc: 0.9529 - val_loss: 0.1608 - val_acc: 0.9473\n",
            "Epoch 48/300\n",
            "825/825 [==============================] - 6s 7ms/step - loss: 0.1356 - acc: 0.9521 - val_loss: 0.1786 - val_acc: 0.9434\n",
            "Epoch 49/300\n",
            "825/825 [==============================] - 6s 7ms/step - loss: 0.1410 - acc: 0.9502 - val_loss: 0.1652 - val_acc: 0.9473\n",
            "Epoch 50/300\n",
            "825/825 [==============================] - 6s 7ms/step - loss: 0.1325 - acc: 0.9550 - val_loss: 0.1676 - val_acc: 0.9458\n",
            "Epoch 51/300\n",
            "825/825 [==============================] - 6s 7ms/step - loss: 0.1349 - acc: 0.9516 - val_loss: 0.1654 - val_acc: 0.9450\n",
            "Epoch 52/300\n",
            "825/825 [==============================] - 6s 7ms/step - loss: 0.1365 - acc: 0.9520 - val_loss: 0.1687 - val_acc: 0.9466\n",
            "Epoch 53/300\n",
            "825/825 [==============================] - 5s 7ms/step - loss: 0.1286 - acc: 0.9548 - val_loss: 0.1624 - val_acc: 0.9486\n",
            "Epoch 54/300\n",
            "825/825 [==============================] - 6s 8ms/step - loss: 0.1373 - acc: 0.9512 - val_loss: 0.1662 - val_acc: 0.9458\n",
            "Epoch 55/300\n",
            "825/825 [==============================] - 6s 7ms/step - loss: 0.1316 - acc: 0.9546 - val_loss: 0.1693 - val_acc: 0.9453\n",
            "Epoch 56/300\n",
            "825/825 [==============================] - 6s 7ms/step - loss: 0.1309 - acc: 0.9547 - val_loss: 0.1651 - val_acc: 0.9478\n",
            "Epoch 57/300\n",
            "825/825 [==============================] - 6s 7ms/step - loss: 0.1336 - acc: 0.9526 - val_loss: 0.1704 - val_acc: 0.9432\n",
            "Epoch 58/300\n",
            "825/825 [==============================] - 6s 7ms/step - loss: 0.1383 - acc: 0.9523 - val_loss: 0.1615 - val_acc: 0.9461\n",
            "Epoch 59/300\n",
            "825/825 [==============================] - 7s 8ms/step - loss: 0.1319 - acc: 0.9531 - val_loss: 0.1655 - val_acc: 0.9478\n",
            "Epoch 60/300\n",
            "825/825 [==============================] - 7s 8ms/step - loss: 0.1312 - acc: 0.9539 - val_loss: 0.1613 - val_acc: 0.9479\n",
            "Epoch 61/300\n",
            "825/825 [==============================] - 7s 8ms/step - loss: 0.1314 - acc: 0.9533 - val_loss: 0.1607 - val_acc: 0.9479\n",
            "Epoch 62/300\n",
            "825/825 [==============================] - 7s 8ms/step - loss: 0.1331 - acc: 0.9521 - val_loss: 0.1585 - val_acc: 0.9470\n",
            "Epoch 63/300\n",
            "825/825 [==============================] - 6s 8ms/step - loss: 0.1296 - acc: 0.9543 - val_loss: 0.1613 - val_acc: 0.9478\n",
            "Epoch 64/300\n",
            "825/825 [==============================] - 6s 7ms/step - loss: 0.1311 - acc: 0.9543 - val_loss: 0.1675 - val_acc: 0.9458\n",
            "Epoch 65/300\n",
            "825/825 [==============================] - 6s 7ms/step - loss: 0.1334 - acc: 0.9526 - val_loss: 0.1552 - val_acc: 0.9497\n",
            "Epoch 66/300\n",
            "825/825 [==============================] - 6s 7ms/step - loss: 0.1339 - acc: 0.9523 - val_loss: 0.1606 - val_acc: 0.9476\n",
            "Epoch 67/300\n",
            "825/825 [==============================] - 6s 7ms/step - loss: 0.1324 - acc: 0.9538 - val_loss: 0.1564 - val_acc: 0.9481\n",
            "Epoch 68/300\n",
            "825/825 [==============================] - 6s 7ms/step - loss: 0.1359 - acc: 0.9498 - val_loss: 0.1545 - val_acc: 0.9491\n",
            "Epoch 69/300\n",
            "825/825 [==============================] - 6s 7ms/step - loss: 0.1323 - acc: 0.9533 - val_loss: 0.1600 - val_acc: 0.9471\n",
            "Epoch 70/300\n",
            "825/825 [==============================] - 6s 7ms/step - loss: 0.1345 - acc: 0.9536 - val_loss: 0.1593 - val_acc: 0.9502\n",
            "Epoch 71/300\n",
            "825/825 [==============================] - 6s 7ms/step - loss: 0.1314 - acc: 0.9530 - val_loss: 0.1595 - val_acc: 0.9487\n",
            "Epoch 72/300\n",
            "825/825 [==============================] - 6s 7ms/step - loss: 0.1270 - acc: 0.9550 - val_loss: 0.1645 - val_acc: 0.9473\n",
            "Epoch 73/300\n",
            "825/825 [==============================] - 6s 7ms/step - loss: 0.1279 - acc: 0.9545 - val_loss: 0.1562 - val_acc: 0.9482\n",
            "Epoch 74/300\n",
            "825/825 [==============================] - 6s 7ms/step - loss: 0.1276 - acc: 0.9558 - val_loss: 0.1483 - val_acc: 0.9492\n",
            "Epoch 75/300\n",
            "825/825 [==============================] - 6s 8ms/step - loss: 0.1302 - acc: 0.9547 - val_loss: 0.1539 - val_acc: 0.9489\n",
            "Epoch 76/300\n",
            "825/825 [==============================] - 6s 7ms/step - loss: 0.1291 - acc: 0.9543 - val_loss: 0.1578 - val_acc: 0.9479\n",
            "Epoch 77/300\n",
            "825/825 [==============================] - 7s 8ms/step - loss: 0.1330 - acc: 0.9532 - val_loss: 0.1561 - val_acc: 0.9474\n",
            "Epoch 78/300\n",
            "825/825 [==============================] - 6s 8ms/step - loss: 0.1251 - acc: 0.9557 - val_loss: 0.1584 - val_acc: 0.9486\n",
            "Epoch 79/300\n",
            "825/825 [==============================] - 6s 8ms/step - loss: 0.1352 - acc: 0.9525 - val_loss: 0.1568 - val_acc: 0.9500\n",
            "Epoch 80/300\n",
            "825/825 [==============================] - 6s 7ms/step - loss: 0.1277 - acc: 0.9548 - val_loss: 0.1520 - val_acc: 0.9505\n",
            "Epoch 81/300\n",
            "825/825 [==============================] - 6s 7ms/step - loss: 0.1287 - acc: 0.9546 - val_loss: 0.1527 - val_acc: 0.9491\n",
            "Epoch 82/300\n",
            "825/825 [==============================] - 6s 7ms/step - loss: 0.1321 - acc: 0.9534 - val_loss: 0.1648 - val_acc: 0.9494\n",
            "Epoch 83/300\n",
            "825/825 [==============================] - 6s 7ms/step - loss: 0.1290 - acc: 0.9543 - val_loss: 0.1537 - val_acc: 0.9505\n",
            "Epoch 84/300\n",
            "825/825 [==============================] - 5s 7ms/step - loss: 0.1240 - acc: 0.9559 - val_loss: 0.1587 - val_acc: 0.9484\n",
            "Epoch 85/300\n",
            "825/825 [==============================] - 6s 7ms/step - loss: 0.1333 - acc: 0.9531 - val_loss: 0.1527 - val_acc: 0.9499\n",
            "Epoch 86/300\n",
            "825/825 [==============================] - 6s 7ms/step - loss: 0.1288 - acc: 0.9548 - val_loss: 0.1626 - val_acc: 0.9497\n",
            "Epoch 87/300\n",
            "825/825 [==============================] - 6s 7ms/step - loss: 0.1326 - acc: 0.9530 - val_loss: 0.1554 - val_acc: 0.9497\n",
            "Epoch 88/300\n",
            "825/825 [==============================] - 6s 7ms/step - loss: 0.1316 - acc: 0.9549 - val_loss: 0.1536 - val_acc: 0.9497\n",
            "Epoch 89/300\n",
            "825/825 [==============================] - 5s 7ms/step - loss: 0.1281 - acc: 0.9552 - val_loss: 0.1547 - val_acc: 0.9502\n",
            "Epoch 90/300\n",
            "825/825 [==============================] - 6s 7ms/step - loss: 0.1268 - acc: 0.9551 - val_loss: 0.1572 - val_acc: 0.9487\n",
            "Epoch 91/300\n",
            "825/825 [==============================] - 6s 7ms/step - loss: 0.1262 - acc: 0.9549 - val_loss: 0.1597 - val_acc: 0.9481\n",
            "Epoch 92/300\n",
            "825/825 [==============================] - 6s 7ms/step - loss: 0.1306 - acc: 0.9542 - val_loss: 0.1496 - val_acc: 0.9500\n",
            "Epoch 93/300\n",
            "825/825 [==============================] - 6s 7ms/step - loss: 0.1272 - acc: 0.9555 - val_loss: 0.1498 - val_acc: 0.9513\n",
            "Epoch 94/300\n",
            "825/825 [==============================] - 5s 7ms/step - loss: 0.1253 - acc: 0.9555 - val_loss: 0.1497 - val_acc: 0.9502\n",
            "Epoch 95/300\n",
            "825/825 [==============================] - 5s 7ms/step - loss: 0.1288 - acc: 0.9545 - val_loss: 0.1552 - val_acc: 0.9503\n",
            "Epoch 96/300\n",
            "825/825 [==============================] - 5s 7ms/step - loss: 0.1309 - acc: 0.9537 - val_loss: 0.1545 - val_acc: 0.9484\n",
            "Epoch 97/300\n",
            "825/825 [==============================] - 5s 6ms/step - loss: 0.1295 - acc: 0.9538 - val_loss: 0.1545 - val_acc: 0.9489\n",
            "Epoch 98/300\n",
            "825/825 [==============================] - 5s 7ms/step - loss: 0.1294 - acc: 0.9546 - val_loss: 0.1511 - val_acc: 0.9500\n",
            "Epoch 99/300\n",
            "825/825 [==============================] - 6s 7ms/step - loss: 0.1373 - acc: 0.9504 - val_loss: 0.1518 - val_acc: 0.9487\n",
            "Epoch 100/300\n",
            "825/825 [==============================] - 5s 7ms/step - loss: 0.1251 - acc: 0.9548 - val_loss: 0.1638 - val_acc: 0.9482\n",
            "Epoch 101/300\n",
            "825/825 [==============================] - 6s 7ms/step - loss: 0.1327 - acc: 0.9540 - val_loss: 0.1525 - val_acc: 0.9503\n",
            "Epoch 102/300\n",
            "825/825 [==============================] - 5s 6ms/step - loss: 0.1316 - acc: 0.9529 - val_loss: 0.1519 - val_acc: 0.9507\n",
            "Epoch 103/300\n",
            "825/825 [==============================] - 5s 7ms/step - loss: 0.1251 - acc: 0.9549 - val_loss: 0.1528 - val_acc: 0.9499\n",
            "Epoch 104/300\n",
            "825/825 [==============================] - 6s 7ms/step - loss: 0.1299 - acc: 0.9535 - val_loss: 0.1518 - val_acc: 0.9502\n",
            "Epoch 105/300\n",
            "825/825 [==============================] - 6s 7ms/step - loss: 0.1279 - acc: 0.9545 - val_loss: 0.1664 - val_acc: 0.9484\n",
            "Epoch 106/300\n",
            "825/825 [==============================] - 6s 7ms/step - loss: 0.1370 - acc: 0.9524 - val_loss: 0.1545 - val_acc: 0.9489\n",
            "Epoch 107/300\n",
            "825/825 [==============================] - 6s 7ms/step - loss: 0.1289 - acc: 0.9546 - val_loss: 0.1513 - val_acc: 0.9508\n",
            "Epoch 108/300\n",
            "825/825 [==============================] - 6s 7ms/step - loss: 0.1272 - acc: 0.9542 - val_loss: 0.1500 - val_acc: 0.9510\n",
            "Epoch 109/300\n",
            "825/825 [==============================] - 6s 7ms/step - loss: 0.1264 - acc: 0.9547 - val_loss: 0.1545 - val_acc: 0.9512\n",
            "Epoch 110/300\n",
            "825/825 [==============================] - 6s 7ms/step - loss: 0.1247 - acc: 0.9552 - val_loss: 0.1515 - val_acc: 0.9502\n",
            "Epoch 111/300\n",
            "825/825 [==============================] - 5s 7ms/step - loss: 0.1268 - acc: 0.9554 - val_loss: 0.1523 - val_acc: 0.9507\n",
            "Epoch 112/300\n",
            "825/825 [==============================] - 6s 7ms/step - loss: 0.1288 - acc: 0.9543 - val_loss: 0.1516 - val_acc: 0.9505\n",
            "Epoch 113/300\n",
            "825/825 [==============================] - 7s 9ms/step - loss: 0.1252 - acc: 0.9550 - val_loss: 0.1522 - val_acc: 0.9507\n",
            "Epoch 114/300\n",
            "825/825 [==============================] - 6s 8ms/step - loss: 0.1242 - acc: 0.9554 - val_loss: 0.1525 - val_acc: 0.9499\n",
            "Epoch 115/300\n",
            "825/825 [==============================] - 6s 7ms/step - loss: 0.1292 - acc: 0.9542 - val_loss: 0.1525 - val_acc: 0.9491\n",
            "Epoch 116/300\n",
            "825/825 [==============================] - 6s 8ms/step - loss: 0.1266 - acc: 0.9552 - val_loss: 0.1530 - val_acc: 0.9500\n",
            "Epoch 117/300\n",
            "825/825 [==============================] - 6s 8ms/step - loss: 0.1335 - acc: 0.9511 - val_loss: 0.1549 - val_acc: 0.9495\n",
            "Epoch 118/300\n",
            "825/825 [==============================] - 6s 8ms/step - loss: 0.1258 - acc: 0.9551 - val_loss: 0.1560 - val_acc: 0.9495\n",
            "Epoch 119/300\n",
            "825/825 [==============================] - 7s 9ms/step - loss: 0.1300 - acc: 0.9539 - val_loss: 0.1572 - val_acc: 0.9502\n",
            "Epoch 120/300\n",
            "825/825 [==============================] - 6s 7ms/step - loss: 0.1295 - acc: 0.9543 - val_loss: 0.1539 - val_acc: 0.9479\n",
            "Epoch 121/300\n",
            "825/825 [==============================] - 6s 7ms/step - loss: 0.1273 - acc: 0.9550 - val_loss: 0.1579 - val_acc: 0.9482\n",
            "Epoch 122/300\n",
            "825/825 [==============================] - 6s 8ms/step - loss: 0.1322 - acc: 0.9538 - val_loss: 0.1568 - val_acc: 0.9491\n",
            "Epoch 123/300\n",
            "825/825 [==============================] - 7s 8ms/step - loss: 0.1306 - acc: 0.9540 - val_loss: 0.1574 - val_acc: 0.9491\n",
            "Epoch 124/300\n",
            "825/825 [==============================] - 7s 8ms/step - loss: 0.1250 - acc: 0.9549 - val_loss: 0.1539 - val_acc: 0.9494\n",
            "Epoch 125/300\n",
            "825/825 [==============================] - 6s 7ms/step - loss: 0.1271 - acc: 0.9543 - val_loss: 0.1527 - val_acc: 0.9494\n",
            "Epoch 126/300\n",
            "825/825 [==============================] - 6s 7ms/step - loss: 0.1227 - acc: 0.9554 - val_loss: 0.1547 - val_acc: 0.9486\n",
            "Epoch 127/300\n",
            "825/825 [==============================] - 6s 7ms/step - loss: 0.1238 - acc: 0.9565 - val_loss: 0.1562 - val_acc: 0.9502\n",
            "Epoch 128/300\n",
            "825/825 [==============================] - 7s 8ms/step - loss: 0.1342 - acc: 0.9529 - val_loss: 0.1535 - val_acc: 0.9494\n",
            "Epoch 129/300\n",
            "825/825 [==============================] - 6s 8ms/step - loss: 0.1264 - acc: 0.9553 - val_loss: 0.1545 - val_acc: 0.9494\n",
            "Epoch 130/300\n",
            "825/825 [==============================] - 6s 7ms/step - loss: 0.1238 - acc: 0.9556 - val_loss: 0.1563 - val_acc: 0.9497\n",
            "Epoch 131/300\n",
            "825/825 [==============================] - 6s 7ms/step - loss: 0.1277 - acc: 0.9554 - val_loss: 0.1591 - val_acc: 0.9502\n",
            "Epoch 132/300\n",
            "825/825 [==============================] - 6s 7ms/step - loss: 0.1265 - acc: 0.9543 - val_loss: 0.1547 - val_acc: 0.9500\n",
            "Epoch 133/300\n",
            "825/825 [==============================] - 6s 7ms/step - loss: 0.1234 - acc: 0.9570 - val_loss: 0.1556 - val_acc: 0.9484\n",
            "Epoch 134/300\n",
            "825/825 [==============================] - 6s 7ms/step - loss: 0.1243 - acc: 0.9574 - val_loss: 0.1574 - val_acc: 0.9492\n",
            "Epoch 135/300\n",
            "825/825 [==============================] - 6s 7ms/step - loss: 0.1271 - acc: 0.9553 - val_loss: 0.1551 - val_acc: 0.9489\n",
            "Epoch 136/300\n",
            "825/825 [==============================] - 6s 7ms/step - loss: 0.1279 - acc: 0.9544 - val_loss: 0.1575 - val_acc: 0.9494\n",
            "Epoch 137/300\n",
            "825/825 [==============================] - 6s 7ms/step - loss: 0.1282 - acc: 0.9549 - val_loss: 0.1537 - val_acc: 0.9497\n",
            "Epoch 138/300\n",
            "825/825 [==============================] - 6s 7ms/step - loss: 0.1281 - acc: 0.9548 - val_loss: 0.1549 - val_acc: 0.9495\n",
            "Epoch 139/300\n",
            "825/825 [==============================] - 6s 7ms/step - loss: 0.1258 - acc: 0.9558 - val_loss: 0.1541 - val_acc: 0.9486\n",
            "Epoch 140/300\n",
            "825/825 [==============================] - 6s 7ms/step - loss: 0.1273 - acc: 0.9542 - val_loss: 0.1553 - val_acc: 0.9503\n",
            "Epoch 141/300\n",
            "825/825 [==============================] - 6s 7ms/step - loss: 0.1302 - acc: 0.9531 - val_loss: 0.1501 - val_acc: 0.9494\n",
            "Epoch 142/300\n",
            "825/825 [==============================] - 6s 7ms/step - loss: 0.1235 - acc: 0.9561 - val_loss: 0.1544 - val_acc: 0.9481\n",
            "Epoch 143/300\n",
            "825/825 [==============================] - 6s 7ms/step - loss: 0.1282 - acc: 0.9542 - val_loss: 0.1534 - val_acc: 0.9476\n",
            "Epoch 144/300\n",
            "825/825 [==============================] - 6s 7ms/step - loss: 0.1342 - acc: 0.9529 - val_loss: 0.1523 - val_acc: 0.9499\n",
            "Epoch 145/300\n",
            "825/825 [==============================] - 6s 8ms/step - loss: 0.1226 - acc: 0.9569 - val_loss: 0.1510 - val_acc: 0.9497\n",
            "Epoch 146/300\n",
            "825/825 [==============================] - 6s 7ms/step - loss: 0.1263 - acc: 0.9549 - val_loss: 0.1564 - val_acc: 0.9497\n",
            "Epoch 147/300\n",
            "825/825 [==============================] - 7s 8ms/step - loss: 0.1269 - acc: 0.9536 - val_loss: 0.1529 - val_acc: 0.9484\n",
            "Epoch 148/300\n",
            "825/825 [==============================] - 6s 7ms/step - loss: 0.1271 - acc: 0.9552 - val_loss: 0.1545 - val_acc: 0.9487\n",
            "Epoch 149/300\n",
            "825/825 [==============================] - 6s 7ms/step - loss: 0.1209 - acc: 0.9572 - val_loss: 0.1551 - val_acc: 0.9503\n",
            "Epoch 150/300\n",
            "825/825 [==============================] - 6s 7ms/step - loss: 0.1283 - acc: 0.9541 - val_loss: 0.1573 - val_acc: 0.9499\n",
            "Epoch 151/300\n",
            "825/825 [==============================] - 6s 7ms/step - loss: 0.1281 - acc: 0.9544 - val_loss: 0.1581 - val_acc: 0.9478\n",
            "Epoch 152/300\n",
            "825/825 [==============================] - 6s 7ms/step - loss: 0.1305 - acc: 0.9536 - val_loss: 0.1583 - val_acc: 0.9487\n",
            "Epoch 153/300\n",
            "825/825 [==============================] - 6s 7ms/step - loss: 0.1288 - acc: 0.9542 - val_loss: 0.1552 - val_acc: 0.9503\n",
            "Epoch 154/300\n",
            "825/825 [==============================] - 6s 8ms/step - loss: 0.1253 - acc: 0.9545 - val_loss: 0.1546 - val_acc: 0.9499\n",
            "Epoch 155/300\n",
            "825/825 [==============================] - 6s 7ms/step - loss: 0.1242 - acc: 0.9557 - val_loss: 0.1561 - val_acc: 0.9499\n",
            "Epoch 156/300\n",
            "825/825 [==============================] - 6s 7ms/step - loss: 0.1247 - acc: 0.9555 - val_loss: 0.1571 - val_acc: 0.9489\n",
            "Epoch 157/300\n",
            "825/825 [==============================] - 6s 7ms/step - loss: 0.1246 - acc: 0.9558 - val_loss: 0.1561 - val_acc: 0.9487\n",
            "Epoch 158/300\n",
            "825/825 [==============================] - 6s 8ms/step - loss: 0.1303 - acc: 0.9533 - val_loss: 0.1577 - val_acc: 0.9482\n",
            "Epoch 159/300\n",
            "825/825 [==============================] - 6s 7ms/step - loss: 0.1259 - acc: 0.9554 - val_loss: 0.1540 - val_acc: 0.9486\n",
            "Epoch 160/300\n",
            "825/825 [==============================] - 7s 8ms/step - loss: 0.1298 - acc: 0.9542 - val_loss: 0.1577 - val_acc: 0.9507\n",
            "Epoch 161/300\n",
            "825/825 [==============================] - 7s 9ms/step - loss: 0.1242 - acc: 0.9550 - val_loss: 0.1575 - val_acc: 0.9497\n",
            "Epoch 162/300\n",
            "825/825 [==============================] - 6s 8ms/step - loss: 0.1274 - acc: 0.9525 - val_loss: 0.1583 - val_acc: 0.9508\n",
            "Epoch 163/300\n",
            "825/825 [==============================] - 6s 8ms/step - loss: 0.1322 - acc: 0.9527 - val_loss: 0.1573 - val_acc: 0.9502\n",
            "Epoch 164/300\n",
            "825/825 [==============================] - 6s 7ms/step - loss: 0.1232 - acc: 0.9561 - val_loss: 0.1605 - val_acc: 0.9502\n",
            "Epoch 165/300\n",
            "825/825 [==============================] - 6s 7ms/step - loss: 0.1313 - acc: 0.9538 - val_loss: 0.1581 - val_acc: 0.9508\n",
            "Epoch 166/300\n",
            "825/825 [==============================] - 6s 7ms/step - loss: 0.1275 - acc: 0.9544 - val_loss: 0.1578 - val_acc: 0.9499\n",
            "Epoch 167/300\n",
            "825/825 [==============================] - 6s 7ms/step - loss: 0.1304 - acc: 0.9538 - val_loss: 0.1565 - val_acc: 0.9500\n",
            "Epoch 168/300\n",
            "825/825 [==============================] - 6s 8ms/step - loss: 0.1282 - acc: 0.9544 - val_loss: 0.1576 - val_acc: 0.9500\n",
            "Epoch 169/300\n",
            "825/825 [==============================] - 6s 8ms/step - loss: 0.1264 - acc: 0.9547 - val_loss: 0.1649 - val_acc: 0.9473\n",
            "Epoch 170/300\n",
            "825/825 [==============================] - 6s 7ms/step - loss: 0.1344 - acc: 0.9531 - val_loss: 0.1566 - val_acc: 0.9497\n",
            "Epoch 171/300\n",
            "825/825 [==============================] - 6s 7ms/step - loss: 0.1255 - acc: 0.9554 - val_loss: 0.1555 - val_acc: 0.9500\n",
            "Epoch 172/300\n",
            "825/825 [==============================] - 6s 7ms/step - loss: 0.1255 - acc: 0.9545 - val_loss: 0.1557 - val_acc: 0.9502\n",
            "Epoch 173/300\n",
            "825/825 [==============================] - 6s 7ms/step - loss: 0.1318 - acc: 0.9527 - val_loss: 0.1588 - val_acc: 0.9499\n",
            "Epoch 174/300\n",
            "825/825 [==============================] - 6s 7ms/step - loss: 0.1224 - acc: 0.9559 - val_loss: 0.1582 - val_acc: 0.9499\n",
            "Epoch 175/300\n",
            "825/825 [==============================] - 6s 8ms/step - loss: 0.1229 - acc: 0.9568 - val_loss: 0.1582 - val_acc: 0.9503\n",
            "Epoch 176/300\n",
            "825/825 [==============================] - 6s 7ms/step - loss: 0.1367 - acc: 0.9512 - val_loss: 0.1514 - val_acc: 0.9487\n",
            "Epoch 177/300\n",
            "825/825 [==============================] - 6s 7ms/step - loss: 0.1263 - acc: 0.9554 - val_loss: 0.1547 - val_acc: 0.9503\n",
            "Epoch 178/300\n",
            "825/825 [==============================] - 6s 7ms/step - loss: 0.1268 - acc: 0.9549 - val_loss: 0.1562 - val_acc: 0.9500\n",
            "Epoch 179/300\n",
            "825/825 [==============================] - 6s 7ms/step - loss: 0.1256 - acc: 0.9553 - val_loss: 0.1565 - val_acc: 0.9502\n",
            "Epoch 180/300\n",
            "825/825 [==============================] - 6s 8ms/step - loss: 0.1259 - acc: 0.9550 - val_loss: 0.1543 - val_acc: 0.9502\n",
            "Epoch 181/300\n",
            "825/825 [==============================] - 6s 7ms/step - loss: 0.1242 - acc: 0.9553 - val_loss: 0.1552 - val_acc: 0.9505\n",
            "Epoch 182/300\n",
            "825/825 [==============================] - 5s 7ms/step - loss: 0.1257 - acc: 0.9554 - val_loss: 0.1588 - val_acc: 0.9494\n",
            "Epoch 183/300\n",
            "825/825 [==============================] - 6s 7ms/step - loss: 0.1252 - acc: 0.9565 - val_loss: 0.1544 - val_acc: 0.9497\n",
            "Epoch 184/300\n",
            "825/825 [==============================] - 6s 7ms/step - loss: 0.1232 - acc: 0.9558 - val_loss: 0.1567 - val_acc: 0.9495\n",
            "Epoch 185/300\n",
            "825/825 [==============================] - 5s 7ms/step - loss: 0.1326 - acc: 0.9534 - val_loss: 0.1538 - val_acc: 0.9499\n",
            "Epoch 186/300\n",
            "825/825 [==============================] - 6s 7ms/step - loss: 0.1247 - acc: 0.9555 - val_loss: 0.1577 - val_acc: 0.9499\n",
            "Epoch 187/300\n",
            "825/825 [==============================] - 6s 7ms/step - loss: 0.1295 - acc: 0.9536 - val_loss: 0.1568 - val_acc: 0.9508\n",
            "Epoch 188/300\n",
            "825/825 [==============================] - 6s 7ms/step - loss: 0.1302 - acc: 0.9534 - val_loss: 0.1503 - val_acc: 0.9502\n",
            "Epoch 189/300\n",
            "825/825 [==============================] - 6s 7ms/step - loss: 0.1260 - acc: 0.9550 - val_loss: 0.1591 - val_acc: 0.9503\n",
            "Epoch 190/300\n",
            "825/825 [==============================] - 5s 7ms/step - loss: 0.1283 - acc: 0.9541 - val_loss: 0.1587 - val_acc: 0.9500\n",
            "Epoch 191/300\n",
            "825/825 [==============================] - 5s 7ms/step - loss: 0.1247 - acc: 0.9556 - val_loss: 0.1491 - val_acc: 0.9500\n",
            "Epoch 192/300\n",
            "825/825 [==============================] - 6s 7ms/step - loss: 0.1263 - acc: 0.9551 - val_loss: 0.1518 - val_acc: 0.9505\n",
            "Epoch 193/300\n",
            "825/825 [==============================] - 6s 7ms/step - loss: 0.1254 - acc: 0.9555 - val_loss: 0.1528 - val_acc: 0.9512\n",
            "Epoch 194/300\n",
            "825/825 [==============================] - 6s 7ms/step - loss: 0.1261 - acc: 0.9548 - val_loss: 0.1526 - val_acc: 0.9510\n",
            "Epoch 195/300\n",
            "825/825 [==============================] - 6s 7ms/step - loss: 0.1232 - acc: 0.9564 - val_loss: 0.1562 - val_acc: 0.9499\n",
            "Epoch 196/300\n",
            "825/825 [==============================] - 5s 7ms/step - loss: 0.1272 - acc: 0.9547 - val_loss: 0.1559 - val_acc: 0.9513\n",
            "Epoch 197/300\n",
            "825/825 [==============================] - 6s 7ms/step - loss: 0.1274 - acc: 0.9550 - val_loss: 0.1555 - val_acc: 0.9507\n",
            "Epoch 198/300\n",
            "825/825 [==============================] - 5s 7ms/step - loss: 0.1222 - acc: 0.9557 - val_loss: 0.1564 - val_acc: 0.9503\n",
            "Epoch 199/300\n",
            "825/825 [==============================] - 5s 7ms/step - loss: 0.1265 - acc: 0.9557 - val_loss: 0.1559 - val_acc: 0.9510\n",
            "Epoch 200/300\n",
            "825/825 [==============================] - 6s 7ms/step - loss: 0.1266 - acc: 0.9555 - val_loss: 0.1570 - val_acc: 0.9505\n",
            "Epoch 201/300\n",
            "825/825 [==============================] - 6s 7ms/step - loss: 0.1242 - acc: 0.9552 - val_loss: 0.1544 - val_acc: 0.9508\n",
            "Epoch 202/300\n",
            "825/825 [==============================] - 6s 7ms/step - loss: 0.1276 - acc: 0.9548 - val_loss: 0.1605 - val_acc: 0.9507\n",
            "Epoch 203/300\n",
            "825/825 [==============================] - 6s 7ms/step - loss: 0.1194 - acc: 0.9577 - val_loss: 0.1534 - val_acc: 0.9507\n",
            "Epoch 204/300\n",
            "825/825 [==============================] - 6s 7ms/step - loss: 0.1244 - acc: 0.9562 - val_loss: 0.1579 - val_acc: 0.9510\n",
            "Epoch 205/300\n",
            "825/825 [==============================] - 6s 7ms/step - loss: 0.1265 - acc: 0.9535 - val_loss: 0.1550 - val_acc: 0.9503\n",
            "Epoch 206/300\n",
            "825/825 [==============================] - 6s 7ms/step - loss: 0.1233 - acc: 0.9559 - val_loss: 0.1545 - val_acc: 0.9512\n",
            "Epoch 207/300\n",
            "825/825 [==============================] - 6s 8ms/step - loss: 0.1267 - acc: 0.9551 - val_loss: 0.1563 - val_acc: 0.9508\n",
            "Epoch 208/300\n",
            "825/825 [==============================] - 6s 7ms/step - loss: 0.1255 - acc: 0.9561 - val_loss: 0.1567 - val_acc: 0.9508\n",
            "Epoch 209/300\n",
            "825/825 [==============================] - 6s 7ms/step - loss: 0.1252 - acc: 0.9541 - val_loss: 0.1558 - val_acc: 0.9513\n",
            "Epoch 210/300\n",
            "825/825 [==============================] - 6s 7ms/step - loss: 0.1287 - acc: 0.9544 - val_loss: 0.1584 - val_acc: 0.9499\n",
            "Epoch 211/300\n",
            "825/825 [==============================] - 6s 7ms/step - loss: 0.1261 - acc: 0.9551 - val_loss: 0.1566 - val_acc: 0.9510\n",
            "Epoch 212/300\n",
            "825/825 [==============================] - 6s 7ms/step - loss: 0.1266 - acc: 0.9543 - val_loss: 0.1554 - val_acc: 0.9495\n",
            "Epoch 213/300\n",
            "825/825 [==============================] - 6s 7ms/step - loss: 0.1294 - acc: 0.9531 - val_loss: 0.1548 - val_acc: 0.9510\n",
            "Epoch 214/300\n",
            "825/825 [==============================] - 7s 8ms/step - loss: 0.1267 - acc: 0.9544 - val_loss: 0.1580 - val_acc: 0.9500\n",
            "Epoch 215/300\n",
            "825/825 [==============================] - 7s 9ms/step - loss: 0.1259 - acc: 0.9552 - val_loss: 0.1550 - val_acc: 0.9520\n",
            "Epoch 216/300\n",
            "825/825 [==============================] - 9s 10ms/step - loss: 0.1258 - acc: 0.9549 - val_loss: 0.1574 - val_acc: 0.9508\n",
            "Epoch 217/300\n",
            "825/825 [==============================] - 10s 12ms/step - loss: 0.1229 - acc: 0.9563 - val_loss: 0.1572 - val_acc: 0.9499\n",
            "Epoch 218/300\n",
            "825/825 [==============================] - 10s 12ms/step - loss: 0.1234 - acc: 0.9550 - val_loss: 0.1639 - val_acc: 0.9495\n",
            "Epoch 219/300\n",
            "825/825 [==============================] - 7s 8ms/step - loss: 0.1335 - acc: 0.9513 - val_loss: 0.1563 - val_acc: 0.9499\n",
            "Epoch 220/300\n",
            "825/825 [==============================] - 7s 8ms/step - loss: 0.1250 - acc: 0.9546 - val_loss: 0.1569 - val_acc: 0.9507\n",
            "Epoch 221/300\n",
            "825/825 [==============================] - 6s 8ms/step - loss: 0.1224 - acc: 0.9569 - val_loss: 0.1555 - val_acc: 0.9507\n",
            "Epoch 222/300\n",
            "825/825 [==============================] - 6s 7ms/step - loss: 0.1260 - acc: 0.9541 - val_loss: 0.1555 - val_acc: 0.9507\n",
            "Epoch 223/300\n",
            "825/825 [==============================] - 6s 7ms/step - loss: 0.1281 - acc: 0.9547 - val_loss: 0.1547 - val_acc: 0.9510\n",
            "Epoch 224/300\n",
            "825/825 [==============================] - 7s 8ms/step - loss: 0.1235 - acc: 0.9568 - val_loss: 0.1553 - val_acc: 0.9508\n",
            "Epoch 225/300\n",
            "825/825 [==============================] - 7s 9ms/step - loss: 0.1249 - acc: 0.9561 - val_loss: 0.1550 - val_acc: 0.9503\n",
            "Epoch 226/300\n",
            "825/825 [==============================] - 8s 9ms/step - loss: 0.1261 - acc: 0.9547 - val_loss: 0.1553 - val_acc: 0.9481\n",
            "Epoch 227/300\n",
            "825/825 [==============================] - 8s 9ms/step - loss: 0.1327 - acc: 0.9537 - val_loss: 0.1515 - val_acc: 0.9497\n",
            "Epoch 228/300\n",
            "825/825 [==============================] - 7s 9ms/step - loss: 0.1321 - acc: 0.9521 - val_loss: 0.1521 - val_acc: 0.9515\n",
            "Epoch 229/300\n",
            "825/825 [==============================] - 6s 8ms/step - loss: 0.1223 - acc: 0.9562 - val_loss: 0.1520 - val_acc: 0.9515\n",
            "Epoch 230/300\n",
            "825/825 [==============================] - 7s 8ms/step - loss: 0.1256 - acc: 0.9535 - val_loss: 0.1523 - val_acc: 0.9513\n",
            "Epoch 231/300\n",
            "825/825 [==============================] - 6s 8ms/step - loss: 0.1224 - acc: 0.9569 - val_loss: 0.1530 - val_acc: 0.9508\n",
            "Epoch 232/300\n",
            "825/825 [==============================] - 6s 8ms/step - loss: 0.1225 - acc: 0.9555 - val_loss: 0.1529 - val_acc: 0.9520\n",
            "Epoch 233/300\n",
            "825/825 [==============================] - 6s 8ms/step - loss: 0.1267 - acc: 0.9542 - val_loss: 0.1515 - val_acc: 0.9510\n",
            "Epoch 234/300\n",
            "825/825 [==============================] - 6s 8ms/step - loss: 0.1250 - acc: 0.9561 - val_loss: 0.1496 - val_acc: 0.9518\n",
            "Epoch 235/300\n",
            "825/825 [==============================] - 6s 8ms/step - loss: 0.1251 - acc: 0.9560 - val_loss: 0.1599 - val_acc: 0.9495\n",
            "Epoch 236/300\n",
            "825/825 [==============================] - 6s 8ms/step - loss: 0.1313 - acc: 0.9542 - val_loss: 0.1533 - val_acc: 0.9499\n",
            "Epoch 237/300\n",
            "825/825 [==============================] - 6s 8ms/step - loss: 0.1301 - acc: 0.9530 - val_loss: 0.1536 - val_acc: 0.9499\n",
            "Epoch 238/300\n",
            "825/825 [==============================] - 7s 8ms/step - loss: 0.1217 - acc: 0.9576 - val_loss: 0.1518 - val_acc: 0.9512\n",
            "Epoch 239/300\n",
            "825/825 [==============================] - 6s 8ms/step - loss: 0.1286 - acc: 0.9540 - val_loss: 0.1543 - val_acc: 0.9502\n",
            "Epoch 240/300\n",
            "825/825 [==============================] - 6s 8ms/step - loss: 0.1231 - acc: 0.9554 - val_loss: 0.1542 - val_acc: 0.9499\n",
            "Epoch 241/300\n",
            "825/825 [==============================] - 6s 8ms/step - loss: 0.1224 - acc: 0.9564 - val_loss: 0.1521 - val_acc: 0.9492\n",
            "Epoch 242/300\n",
            "825/825 [==============================] - 6s 7ms/step - loss: 0.1243 - acc: 0.9547 - val_loss: 0.1530 - val_acc: 0.9512\n",
            "Epoch 243/300\n",
            "825/825 [==============================] - 6s 7ms/step - loss: 0.1305 - acc: 0.9541 - val_loss: 0.1528 - val_acc: 0.9499\n",
            "Epoch 244/300\n",
            "825/825 [==============================] - 6s 7ms/step - loss: 0.1266 - acc: 0.9550 - val_loss: 0.1501 - val_acc: 0.9495\n",
            "Epoch 245/300\n",
            "825/825 [==============================] - 6s 8ms/step - loss: 0.1281 - acc: 0.9540 - val_loss: 0.1504 - val_acc: 0.9518\n",
            "Epoch 246/300\n",
            "825/825 [==============================] - 7s 8ms/step - loss: 0.1241 - acc: 0.9564 - val_loss: 0.1523 - val_acc: 0.9508\n",
            "Epoch 247/300\n",
            "825/825 [==============================] - 6s 7ms/step - loss: 0.1251 - acc: 0.9555 - val_loss: 0.1532 - val_acc: 0.9495\n",
            "Epoch 248/300\n",
            "825/825 [==============================] - 7s 8ms/step - loss: 0.1263 - acc: 0.9541 - val_loss: 0.1531 - val_acc: 0.9520\n",
            "Epoch 249/300\n",
            "825/825 [==============================] - 6s 8ms/step - loss: 0.1298 - acc: 0.9540 - val_loss: 0.1496 - val_acc: 0.9513\n",
            "Epoch 250/300\n",
            "825/825 [==============================] - 6s 7ms/step - loss: 0.1237 - acc: 0.9560 - val_loss: 0.1484 - val_acc: 0.9505\n",
            "Epoch 251/300\n",
            "825/825 [==============================] - 6s 7ms/step - loss: 0.1253 - acc: 0.9556 - val_loss: 0.1498 - val_acc: 0.9503\n",
            "Epoch 252/300\n",
            "825/825 [==============================] - 7s 8ms/step - loss: 0.1317 - acc: 0.9532 - val_loss: 0.1538 - val_acc: 0.9500\n",
            "Epoch 253/300\n",
            "825/825 [==============================] - 6s 8ms/step - loss: 0.1266 - acc: 0.9532 - val_loss: 0.1531 - val_acc: 0.9505\n",
            "Epoch 254/300\n",
            "825/825 [==============================] - 6s 8ms/step - loss: 0.1266 - acc: 0.9554 - val_loss: 0.1518 - val_acc: 0.9503\n",
            "Epoch 255/300\n",
            "825/825 [==============================] - 5s 7ms/step - loss: 0.1271 - acc: 0.9536 - val_loss: 0.1514 - val_acc: 0.9523\n",
            "Epoch 256/300\n",
            "825/825 [==============================] - 5s 6ms/step - loss: 0.1222 - acc: 0.9560 - val_loss: 0.1707 - val_acc: 0.9476\n",
            "Epoch 257/300\n",
            "825/825 [==============================] - 6s 7ms/step - loss: 0.1306 - acc: 0.9543 - val_loss: 0.1539 - val_acc: 0.9499\n",
            "Epoch 258/300\n",
            "825/825 [==============================] - 5s 7ms/step - loss: 0.1249 - acc: 0.9562 - val_loss: 0.1555 - val_acc: 0.9500\n",
            "Epoch 259/300\n",
            "825/825 [==============================] - 5s 6ms/step - loss: 0.1277 - acc: 0.9540 - val_loss: 0.1547 - val_acc: 0.9513\n",
            "Epoch 260/300\n",
            "825/825 [==============================] - 6s 7ms/step - loss: 0.1203 - acc: 0.9571 - val_loss: 0.1542 - val_acc: 0.9513\n",
            "Epoch 261/300\n",
            "825/825 [==============================] - 5s 7ms/step - loss: 0.1289 - acc: 0.9539 - val_loss: 0.1516 - val_acc: 0.9502\n",
            "Epoch 262/300\n",
            "825/825 [==============================] - 6s 7ms/step - loss: 0.1252 - acc: 0.9546 - val_loss: 0.1507 - val_acc: 0.9513\n",
            "Epoch 263/300\n",
            "825/825 [==============================] - 5s 7ms/step - loss: 0.1287 - acc: 0.9562 - val_loss: 0.1508 - val_acc: 0.9513\n",
            "Epoch 264/300\n",
            "825/825 [==============================] - 5s 6ms/step - loss: 0.1248 - acc: 0.9554 - val_loss: 0.1495 - val_acc: 0.9513\n",
            "Epoch 265/300\n",
            "825/825 [==============================] - 6s 7ms/step - loss: 0.1235 - acc: 0.9563 - val_loss: 0.1485 - val_acc: 0.9512\n",
            "Epoch 266/300\n",
            "825/825 [==============================] - 5s 7ms/step - loss: 0.1248 - acc: 0.9550 - val_loss: 0.1495 - val_acc: 0.9510\n",
            "Epoch 267/300\n",
            "825/825 [==============================] - 6s 7ms/step - loss: 0.1238 - acc: 0.9552 - val_loss: 0.1485 - val_acc: 0.9508\n",
            "Epoch 268/300\n",
            "825/825 [==============================] - 6s 7ms/step - loss: 0.1203 - acc: 0.9565 - val_loss: 0.1503 - val_acc: 0.9505\n",
            "Epoch 269/300\n",
            "825/825 [==============================] - 6s 8ms/step - loss: 0.1300 - acc: 0.9533 - val_loss: 0.1555 - val_acc: 0.9495\n",
            "Epoch 270/300\n",
            "825/825 [==============================] - 6s 8ms/step - loss: 0.1299 - acc: 0.9536 - val_loss: 0.1499 - val_acc: 0.9508\n",
            "Epoch 271/300\n",
            "825/825 [==============================] - 6s 7ms/step - loss: 0.1209 - acc: 0.9577 - val_loss: 0.1502 - val_acc: 0.9510\n",
            "Epoch 272/300\n",
            "825/825 [==============================] - 6s 7ms/step - loss: 0.1227 - acc: 0.9574 - val_loss: 0.1512 - val_acc: 0.9508\n",
            "Epoch 273/300\n",
            "825/825 [==============================] - 6s 7ms/step - loss: 0.1273 - acc: 0.9532 - val_loss: 0.1543 - val_acc: 0.9499\n",
            "Epoch 274/300\n",
            "825/825 [==============================] - 6s 7ms/step - loss: 0.1278 - acc: 0.9542 - val_loss: 0.1519 - val_acc: 0.9505\n",
            "Epoch 275/300\n",
            "825/825 [==============================] - 6s 7ms/step - loss: 0.1309 - acc: 0.9533 - val_loss: 0.1484 - val_acc: 0.9508\n",
            "Epoch 276/300\n",
            "825/825 [==============================] - 6s 7ms/step - loss: 0.1257 - acc: 0.9551 - val_loss: 0.1488 - val_acc: 0.9512\n",
            "Epoch 277/300\n",
            "825/825 [==============================] - 6s 7ms/step - loss: 0.1209 - acc: 0.9569 - val_loss: 0.1508 - val_acc: 0.9513\n",
            "Epoch 278/300\n",
            "825/825 [==============================] - 6s 7ms/step - loss: 0.1194 - acc: 0.9566 - val_loss: 0.1498 - val_acc: 0.9507\n",
            "Epoch 279/300\n",
            "825/825 [==============================] - 6s 7ms/step - loss: 0.1263 - acc: 0.9551 - val_loss: 0.1478 - val_acc: 0.9507\n",
            "Epoch 280/300\n",
            "825/825 [==============================] - 6s 7ms/step - loss: 0.1210 - acc: 0.9567 - val_loss: 0.1495 - val_acc: 0.9513\n",
            "Epoch 281/300\n",
            "825/825 [==============================] - 6s 7ms/step - loss: 0.1250 - acc: 0.9559 - val_loss: 0.1502 - val_acc: 0.9513\n",
            "Epoch 282/300\n",
            "825/825 [==============================] - 6s 7ms/step - loss: 0.1314 - acc: 0.9528 - val_loss: 0.1545 - val_acc: 0.9491\n",
            "Epoch 283/300\n",
            "825/825 [==============================] - 6s 7ms/step - loss: 0.1264 - acc: 0.9551 - val_loss: 0.1486 - val_acc: 0.9503\n",
            "Epoch 284/300\n",
            "825/825 [==============================] - 7s 8ms/step - loss: 0.1271 - acc: 0.9543 - val_loss: 0.1492 - val_acc: 0.9507\n",
            "Epoch 285/300\n",
            "825/825 [==============================] - 8s 10ms/step - loss: 0.1239 - acc: 0.9564 - val_loss: 0.1493 - val_acc: 0.9507\n",
            "Epoch 286/300\n",
            "825/825 [==============================] - 7s 8ms/step - loss: 0.1217 - acc: 0.9573 - val_loss: 0.1502 - val_acc: 0.9503\n",
            "Epoch 287/300\n",
            "825/825 [==============================] - 6s 7ms/step - loss: 0.1282 - acc: 0.9540 - val_loss: 0.1570 - val_acc: 0.9478\n",
            "Epoch 288/300\n",
            "825/825 [==============================] - 6s 7ms/step - loss: 0.1279 - acc: 0.9537 - val_loss: 0.1483 - val_acc: 0.9513\n",
            "Epoch 289/300\n",
            "825/825 [==============================] - 6s 7ms/step - loss: 0.1236 - acc: 0.9561 - val_loss: 0.1494 - val_acc: 0.9513\n",
            "Epoch 290/300\n",
            "825/825 [==============================] - 6s 8ms/step - loss: 0.1261 - acc: 0.9557 - val_loss: 0.1509 - val_acc: 0.9513\n",
            "Epoch 291/300\n",
            "825/825 [==============================] - 6s 8ms/step - loss: 0.1292 - acc: 0.9536 - val_loss: 0.1501 - val_acc: 0.9508\n",
            "Epoch 292/300\n",
            "825/825 [==============================] - 7s 8ms/step - loss: 0.1215 - acc: 0.9567 - val_loss: 0.1498 - val_acc: 0.9505\n",
            "Epoch 293/300\n",
            "825/825 [==============================] - 6s 7ms/step - loss: 0.1263 - acc: 0.9549 - val_loss: 0.1533 - val_acc: 0.9503\n",
            "Epoch 294/300\n",
            "825/825 [==============================] - 6s 8ms/step - loss: 0.1274 - acc: 0.9563 - val_loss: 0.1502 - val_acc: 0.9508\n",
            "Epoch 295/300\n",
            "825/825 [==============================] - 6s 8ms/step - loss: 0.1282 - acc: 0.9543 - val_loss: 0.1583 - val_acc: 0.9482\n",
            "Epoch 296/300\n",
            "825/825 [==============================] - 6s 7ms/step - loss: 0.1295 - acc: 0.9548 - val_loss: 0.1489 - val_acc: 0.9508\n",
            "Epoch 297/300\n",
            "825/825 [==============================] - 6s 7ms/step - loss: 0.1267 - acc: 0.9547 - val_loss: 0.1510 - val_acc: 0.9510\n",
            "Epoch 298/300\n",
            "825/825 [==============================] - 6s 7ms/step - loss: 0.1275 - acc: 0.9527 - val_loss: 0.1504 - val_acc: 0.9507\n",
            "Epoch 299/300\n",
            "825/825 [==============================] - 6s 7ms/step - loss: 0.1223 - acc: 0.9577 - val_loss: 0.1517 - val_acc: 0.9492\n",
            "Epoch 300/300\n",
            "825/825 [==============================] - 6s 8ms/step - loss: 0.1238 - acc: 0.9554 - val_loss: 0.1502 - val_acc: 0.9515\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7PN43Ye3nmf-"
      },
      "source": [
        "score = model.evaluate(X_test, y_test, verbose=1)\n",
        "\n",
        "print(\"Test Score:\", score[0])\n",
        "print(\"Test Accuracy:\", score[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "id": "v0KURbo_pQGf",
        "outputId": "2d63c8e0-1949-422e-8137-db7918dd9a3a"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import figure\n",
        "\n",
        "figure(figsize=(3, 2), dpi=80)\n",
        "\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "\n",
        "plt.title('LSTM 50-dim GloVe: model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylim((0.5,1.0))\n",
        "plt.legend(['train','test'], loc='lower right')\n",
        "plt.show()\n",
        "\n",
        "plt.figure()\n",
        "figure(figsize=(3, 2), dpi=80)\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "\n",
        "plt.title('LSTM 50-dim GloVe: model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylim((0,1.0))\n",
        "plt.legend(['train','test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 240x160 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x432 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 240x160 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mKngrOvoFxAT"
      },
      "source": [
        "y_test_labels = np.zeros(y_test.shape[0],)\n",
        "for i in range(y_test.shape[0]):\n",
        "  if y_test[i,0] == 1:\n",
        "    y_test_labels[i] = 0\n",
        "  elif y_test[i,1] == 1:\n",
        "    y_test_labels[i] = 1\n",
        "  elif y_test[i,2] == 1:\n",
        "    y_test_labels[i] = 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AT2Llcv1rQUH"
      },
      "source": [
        "predictions = model.predict(X_test)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "predict_labels = np.zeros((X_test.shape[0],))\n",
        "for i in range(predictions.shape[0]):\n",
        "    idx = np.argmax(predictions[i,:])\n",
        "    predict_labels[i] = idx\n",
        "confusion_matrix(y_test_labels, predict_labels, normalize='true')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZH9fVeoEdu7"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "from sklearn import metrics\n",
        "print(classification_report(y_test_labels, predict_labels))\n",
        "print(confusion_matrix(y_test_labels, predict_labels, normalize='true'))\n",
        "print(\"Accuracy:\",metrics.accuracy_score(y_test_labels, predict_labels))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}