{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "K-Nearest Neighbors.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Vf-lqCfM3V1"
      },
      "source": [
        "# K-Nearest Neighbors\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FTnP71OAOxuG"
      },
      "source": [
        "References:\n",
        "\n",
        "How to implement k-nearest neighbors- https://appliedmachinelearning.blog/2018/01/18/conventional-approach-to-text-classification-clustering-using-k-nearest-neighbor-k-means-python-implementation/\n",
        "\n",
        "Varying n_neighbors - https://stackabuse.com/k-nearest-neighbors-algorithm-in-python-and-scikit-learn/\n",
        "\n",
        "Accuracy measure - https://www.datacamp.com/community/tutorials/k-nearest-neighbor-classification-scikit-learn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0JOMauYJNcvA"
      },
      "source": [
        "# Pre-processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kEPuuOA8Mwrz"
      },
      "source": [
        "Imports and loading dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YuNtnjnsYFRQ"
      },
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "import re\n",
        "import numpy as np\n",
        "import warnings\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from nltk.corpus import stopwords\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y2IpeubkbAGC"
      },
      "source": [
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OOFPwaLsYStj"
      },
      "source": [
        "df = pd.read_csv('train1_full.csv') \n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RzrcBXLrZL0Z"
      },
      "source": [
        "# Here we transform the documents into sentences\n",
        "def preprocess(df):\n",
        "    df['comment_text'] = df.comment_text.str.lower()\n",
        "    df['document_sentences'] = df.comment_text.str.split('.') \n",
        "    df['tokenized_sentences'] = list(map(lambda sentences: list(map(nltk.word_tokenize, sentences)), df.document_sentences))  \n",
        "    df['tokenized_sentences'] = list(map(lambda sentences: list(filter(lambda lst: lst, sentences)), df.tokenized_sentences))\n",
        "\n",
        "preprocess(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_-RzvtoSaI0c"
      },
      "source": [
        "Split data into training and test sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HlG5SC_EZWU6"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train, test, y_train, y_test = train_test_split(df.drop(columns='label'), df['label'], test_size=.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q9cIgWYjlyvO"
      },
      "source": [
        "def remove_items(test_list, item):\n",
        "    # utility function to remove stop words\n",
        "    for i in test_list:\n",
        "        if(i == item):\n",
        "            test_list.remove(i)\n",
        "  \n",
        "    return test_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_ovXsHol0ez"
      },
      "source": [
        "def preprocess_text(sen):\n",
        "    sentence = sen.lower()\n",
        "    # Remove punctuations and numbers\n",
        "    sentence = re.sub('[^a-zA-Z]', ' ', sentence)\n",
        "\n",
        "    # Single character removal\n",
        "    sentence = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', sentence)\n",
        "\n",
        "    # Removing multiple spaces\n",
        "    sentence = re.sub(r'\\s+', ' ', sentence)\n",
        "\n",
        "    # Remove extra spaces\n",
        "    sentence = re.sub(' +', ' ', sentence)\n",
        "    sentence_list = sentence.split()\n",
        "\n",
        "    # Removing stop words\n",
        "    stop_words = ['u', 'ur', 'im', 'can', 'cant', 'i', 'me', 'my', 'myself', 'we', 'go', 'our', 'ours', 'ourselves', 'you', \"youre\", \"youve\", \"youll\", \"youd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'it', 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"thatll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"shouldve\", 'now', 'd', 'll', 'm', 'o', 're', 'r', 'ur', 've', 'y', 'ain', 'aren', \"arent\", 'couldn', \"couldnt\", 'didn', \"didnt\", 'doesn', \"doesnt\", 'hadn', \"hadnt\", 'hasn', \"hasnt\", 'haven', \"havent\", 'isn', \"isnt\", 'ma', 'mightn', \"mightnt\", 'mustn', \"mustnt\", 'needn', \"neednt\", 'shan', \"shant\", 'shouldn', \"shouldnt\", 'wasn', \"wasnt\", 'weren', \"werent\", 'won', \"wont\", 'wouldn', \"wouldnt\"]\n",
        "    for stop_word in stop_words:\n",
        "      if stop_word in sentence_list:\n",
        "        sentence_list = remove_items(sentence_list, stop_word)\n",
        "\n",
        "    # Join back to list\n",
        "    sentence = \" \".join(sentence_list)\n",
        "\n",
        "    # Remove extra spaces\n",
        "    sentence = re.sub(' +', ' ', sentence)\n",
        "    return sentence.lstrip()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kcq-m6qHNpxn"
      },
      "source": [
        "Get a list of all messages and labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z1NSdlRdl3UK"
      },
      "source": [
        "X_train = []\n",
        "sentences = list(train[\"comment_text\"])\n",
        "for sen in sentences:\n",
        "    X_train.append(preprocess_text(sen))  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UecOcQczmm3K"
      },
      "source": [
        "X_test = []\n",
        "sentences1 = list(test[\"comment_text\"])\n",
        "for sen in sentences1:\n",
        "    X_test.append(preprocess_text(sen))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Tn40FYcNxqa"
      },
      "source": [
        "# Tokenizing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o_VT7rCyN1IZ"
      },
      "source": [
        "Use the TfidfVectorizer class to convert the sentences into matrices (the X_train and X_test matrices)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHcJeR6em2fL"
      },
      "source": [
        "vectorizer = TfidfVectorizer(stop_words='english')\n",
        "X_train_matrix = vectorizer.fit_transform(X_train)\n",
        "X_test_matrix = vectorizer.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V2HPAsOYOhrU"
      },
      "source": [
        "# Training and Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ubwfCBA8OcY0"
      },
      "source": [
        "Train and predict with the model for 10 different values of n_neighbors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AIdxAHKeZsJs"
      },
      "source": [
        "from sklearn import metrics\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "accuracy = []\n",
        "matrices = [[]]\n",
        "reports = []\n",
        "\n",
        "for i in range(1, 11):\n",
        "    knn = KNeighborsClassifier(n_neighbors=i)\n",
        "    knn.fit(X_train_matrix,y_train)\n",
        "    prediction = knn.predict(X_test_matrix)\n",
        "    accuracy.append(metrics.accuracy_score(y_test, prediction))\n",
        "    matrices.append(confusion_matrix(y_test, prediction, normalize='true'))\n",
        "    reports.append(classification_report(y_test,prediction))\n",
        "\n",
        "matrices.remove([])\n",
        "for i in range(len(matrices)):\n",
        "  print(\"n_neighbors = \" + str(i + 1) + \":\", \" \")\n",
        "  print(\"Accuracy: \" + str(accuracy[i]))\n",
        "  print(matrices[i])\n",
        "  print(reports[i])\n",
        "  print(\" \")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vG9QP_8_rRyZ"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(range(1, 11), accuracy, color='red', linestyle='dashed', marker='o',\n",
        "         markerfacecolor='blue', markersize=10)\n",
        "plt.title('Accuracy Rate K Value')\n",
        "plt.xlabel('K Value')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}